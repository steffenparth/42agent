# ASI:One Agent Project

A complete ASI:One compatible agent implementation using the uAgents framework and chat protocol.

## 📁 Project Structure

```
.asi-agent/
├── ai_agent.py      # Main ASI:One agent implementation
├── client.py        # Client for communicating with the agent
├── llm.py          # ASI:One LLM API integration
├── chat_proto.py   # Chat protocol definitions
├── requirements.txt # Python dependencies
└── README.md       # This file
```

## 🚀 Quick Start

### 1. Install Dependencies

```bash
cd .asi-agent
pip install -r requirements.txt
```

### 2. Set Environment Variables

```bash
export ASI1_API_KEY="your-asi-one-api-key-here"
```

### 3. Start the ASI:One Agent

```bash
python ai_agent.py
```

You should see output like:
```
🤖 Starting ASI:One Agent...
🚀 ASI:One Agent started successfully!
📍 Agent address: agent1q2cduhv4z5cleynmmlwymluazp0wux3rz2t8a2qtu0ul
🤖 Agent name: asi-agent
📧 Mailbox enabled: True
🌐 Agent inspector: https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address=agent1q2cduhv4z5cleynmmlwymluazp0wux3rz2t8a2qtu0ul
```

### 4. Start the Client (in a new terminal)

```bash
python client.py
```

Enter the agent address when prompted, then start chatting!

## 📋 Features

### 🤖 ASI:One Agent (`ai_agent.py`)
- **Chat Protocol Compliance**: Implements the ASI:One chat protocol
- **LLM Integration**: Connects to ASI:One's LLM API for intelligent responses
- **Message Handling**: Processes incoming messages and sends acknowledgments
- **Error Handling**: Comprehensive error handling and logging
- **Session Management**: Maintains conversation context
- **Mailbox Support**: Enables Agentverse integration

### 💬 Client (`client.py`)
- **Interactive Chat**: Real-time chat interface with the agent
- **Message Sending**: Send messages to the ASI:One agent
- **Response Handling**: Receive and display agent responses
- **Acknowledgment Support**: Handles chat protocol acknowledgments

### 🧠 LLM Integration (`llm.py`)
- **ASI:One API**: Direct integration with ASI:One's chat completions API
- **Error Handling**: Robust error handling for API calls
- **Rate Limiting**: Built-in rate limiting support
- **Response Processing**: Clean extraction of completion text

### 📡 Chat Protocol (`chat_proto.py`)
- **Protocol Definitions**: All necessary chat protocol components
- **Message Types**: Support for ChatMessage, ChatAcknowledgement, TextContent
- **ASI:One Compatibility**: Fully compatible with ASI:One's expected format

## 🔧 Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `ASI1_API_KEY` | Your ASI:One API key | Yes |

### Agent Configuration

The agent is configured with:
- **Name**: `asi-agent`
- **Port**: `8000`
- **Mailbox**: `True` (for Agentverse integration)
- **Publish Details**: `True` (for discoverability)

## 📡 API Endpoints

### ASI:One LLM API
- **URL**: `https://api.asi1.ai/v1/chat/completions`
- **Model**: `asi1-mini`
- **Authentication**: Bearer token via `ASI1_API_KEY`

### Agent Inspector
- **URL**: `https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address={AGENT_ADDRESS}`
- **Purpose**: Monitor and inspect agent activity

## 💬 Chat Protocol

The agent implements the ASI:One chat protocol with:

### Message Flow
1. **Client** sends `ChatMessage` to agent
2. **Agent** sends `ChatAcknowledgement` back
3. **Agent** processes message through ASI:One LLM
4. **Agent** sends response `ChatMessage` to client
5. **Client** sends `ChatAcknowledgement` back

### Message Types
- `ChatMessage`: Contains the actual message content
- `ChatAcknowledgement`: Confirms message receipt
- `TextContent`: Text-based message content

## 🛠️ Development

### Running in Development Mode

```bash
# Terminal 1: Start the agent
python ai_agent.py

# Terminal 2: Start the client
python client.py
```

### Testing the Agent

1. Start the agent and note its address
2. Use the client to send test messages
3. Verify responses are generated by ASI:One LLM
4. Check acknowledgments are properly sent/received

### Debugging

Enable debug logging by setting the log level:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## 🚀 Deployment

### Local Deployment
The agent runs locally on port 8000 with mailbox enabled for Agentverse integration.

### Agentverse Deployment
The agent is configured for Agentverse deployment with:
- `mailbox=True`: Enables Agentverse mailbox
- `publish_agent_details=True`: Makes agent discoverable
- Chat protocol compliance for ASI:One integration

## 📊 Monitoring

### Agent Inspector
Monitor your agent at:
```
https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8000&address={AGENT_ADDRESS}
```

### Logs
The agent provides comprehensive logging:
- Startup/shutdown events
- Message processing
- API calls and responses
- Error conditions

## 🔒 Security

### API Key Security
- Store `ASI1_API_KEY` in environment variables
- Never commit API keys to version control
- Use `.env` files for local development

### Message Validation
- All incoming messages are validated
- Error handling prevents crashes
- Rate limiting prevents abuse

## 🐛 Troubleshooting

### Common Issues

1. **"ASI1_API_KEY environment variable not set"**
   - Set the environment variable: `export ASI1_API_KEY="your-key"`

2. **"Request failed"**
   - Check your internet connection
   - Verify your API key is valid
   - Check ASI:One service status

3. **"Invalid response format"**
   - ASI:One API may have changed
   - Check the API documentation
   - Update the response parsing logic

4. **Agent not responding**
   - Verify the agent is running
   - Check the agent address is correct
   - Ensure both agent and client are on the same network

### Debug Commands

```bash
# Check if agent is running
curl http://localhost:8000/health

# Test ASI:One API directly
curl -X POST https://api.asi1.ai/v1/chat/completions \
  -H "Authorization: bearer $ASI1_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"asi1-mini","messages":[{"role":"user","content":"Hello"}]}'
```

## 📚 API Reference

### ASI:One LLM API

```python
from llm import get_completion, get_completion_text

# Get full response
response = await get_completion(context="", prompt="Hello")

# Get just the text
text = await get_completion_text(context="", prompt="Hello")
```

### Chat Protocol

```python
from chat_proto import ChatMessage, ChatAcknowledgement, TextContent

# Create a message
msg = ChatMessage(
    timestamp=datetime.now(),
    msg_id=uuid4(),
    content=[TextContent(type="text", text="Hello")]
)

# Create acknowledgment
ack = ChatAcknowledgement(
    timestamp=datetime.now(),
    acknowledged_msg_id=msg.msg_id
)
```

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## 📄 License

This project is part of the ETH Global hackathon with Fetch.ai.

## 🔗 Links

- [ASI:One Documentation](https://innovationlab.fetch.ai/resources/docs/asione/)
- [uAgents Framework](https://docs.uagents.ai/)
- [Agentverse](https://agentverse.ai/)
- [Fetch.ai Innovation Lab](https://innovationlab.fetch.ai/) 